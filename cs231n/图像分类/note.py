'''
图像分类(上) -- 图像分类、数据驱动方法和流程

以下图为例，图像分类模型读取该图片，并生成该图片属于集合 {cat, dog, hat, mug}
中各个标签的概率。需要注意的是，对于计算机来说，图像是一个由数字组成的巨大的3维数组。
在这个例子中，猫的图像大小是宽248像素，高400像素，有3个颜色通道，分别是红、绿和蓝（简称RGB）
如此，该图像就包含了248X400X3=297600个数字，每个数字都是在范围0-255之间的整型，其中0表示全黑，255表示全白。
我们的任务就是把这些上百万的数字变成一个简单的标签，比如“猫”
'''

'''
图像分类的任务，就是对于一个给定的图像，预测它所属于的那个分类标签。
（或者给出属于一系列不同标签的可能性）。图像是3维数组，数组元素是取值范围从0到255的整数。
  数组的尺寸是宽度x高度x3，其中这个3代表的是红、绿和蓝3个颜色通道。
困难: 视角变化 大小变化  形变 遮挡 光照条件 背景干扰  类内差异
'''

'''
数据驱动方法:
给计算机很多数据，然后实现学习算法，让计算机学习到每个类的外形。这种方法，就是数据驱动方法。
既然该方法的第一步就是收集已经做好分类标注的图片来作为训练集，那么下面就看看数据库到底长什么样：
'''

'''
图像分类流程:
输入：输入是包含N个图像的集合，每个图像的标签是K种分类标签中的一种。这个集合称为训练集。

学习：这一步的任务是使用训练集来学习每个类到底长什么样。
        一般该步骤叫做训练分类器或者学习一个模型。
评价：让分类器来预测它未曾见过的图像的分类标签，并以此来评价分类器的质量。
        我们会把分类器预测的标签和图像真正的分类标签对比。
        毫无疑问，分类器预测的分类标签和图像真正的分类标签如果一致，那就是好事，
        这样的情况越多越好。
'''








'''
图像分类(下) -- 验证集 交叉验证集 和 超参数调优

用于超参数调优的验证集
    k-NN分类器需要设定k值，那么选择哪个k值最合适的呢？我们可以选择不同的距离函数，比如L1范数和L2范数等，
    那么选哪个好？还有不少选择我们甚至连考虑都没有考虑到（比如：点积）。所有这些选择，
    被称为超参数（hyperparameter）。

    决不能使用测试集来进行调优 算法对测试集过拟合。测试数据集只使用一次，即在训练完成后评价最终的模型时使用。
    
    从训练集中取出一部分数据用来调优，我们称之为验证集（validation set）。以CIFAR-10为例，
    可以用49000个图像作为训练集，用1000个图像作为验证集。验证集其实就是作为假的测试集来调优。

交叉验证:
    有时候，训练集数量较小（因此验证集的数量更小），人们会使用一种被称为交叉验证的方法，这种方法更加复杂些。
    还是用刚才的例子，如果是交叉验证集，我们就不是取1000个图像，而是将训练集平均分成5份，其中4份用来训练，
    1份用来验证。然后我们循环着取其中4份来训练，其中1份来验证，最后取所有5次验证结果的平均值作为算法验证结果。


Nearest Neighbor分类器的优劣
    首先，Nearest Neighbor分类器易于理解，实现简单。其次，算法的训练不需要花时间，
    因为其训练过程只是将训练集数据存储起来。然而测试要花费大量时间计算，
    因为每个测试图像需要和所有存储的训练图像进行比较，这显然是一个缺点。
    在实际应用中，我们关注测试效率远远高于训练效率。


    Nearest Neighbor分类器在某些特定情况（比如数据维度较低）下，可能是不错的选择。
    但是在实际的图像分类工作中，很少使用。因为图像都是高维度数据（他们通常包含很多像素），
    而高维度向量之间的距离通常是反直觉的。
'''

'''
小结: 实际应用k-NN
如果你希望将k-NN分类器用到实处（最好别用到图像上，若是仅仅作为练手还可以接受），那么可以按照以下流程：

1. 数据预处理: 对你数据中的特征进行归一化（normalize），
   让其具有零平均值（zero mean）和单位方差（unit variance）。在后面的小节我们会讨论这些细节。
   本小节不讨论，是因为图像中的像素都是同质的，不会表现出较大的差异分布，也就不需要标准化处理了。

2. 如果数据是高维数据，考虑使用降维方法 ， 比如PCA

3. 将数据随机分入训练集和验证集。按照一般规律，70%-90% 数据作为训练集。
   这个比例根据算法中有多少超参数，以及这些超参数对于算法的预期影响来决定。
   如果需要预测的超参数很多，那么就应该使用更大的验证集来有效地估计它们。
   如果担心验证集数量不够，那么就尝试交叉验证方法。如果计算资源足够，
   使用交叉验证总是更加安全的（份数越多，效果越好，也更耗费计算资源）。

4. 在验证集上调优，尝试足够多的k值，尝试L1和L2两种范数计算方式。

5. 如果分类器跑得太慢，尝试使用Approximate Nearest Neighbor库（比如FLANN）来加速这个过程，
   其代价是降低一些准确率。
   
6. 对最优的超参数做记录。记录最优参数后，是否应该让使用最优参数的算法在完整的训练集上运行并再次训练呢？
   因为如果把验证集重新放回到训练集中（自然训练集的数据量就又变大了），有可能最优参数又会有所变化。
   在实践中，不要这样做。千万不要在最终的分类器中使用验证集数据，这样做会破坏对于最优参数的估计。
   直接使用测试集来测试用最优参数设置好的最优模型，得到测试集数据的分类准确率，
   并以此作为你的kNN分类器在该数据上的性能表现。
'''
